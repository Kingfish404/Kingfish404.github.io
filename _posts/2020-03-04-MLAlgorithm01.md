---
layout: post
title: 机器学习算法入门笔记
date: 2020-03-04
Author: Kingfish404
tags: [机器学习]
comments: true
toc: true
description: 2020年初机器学习的一些入门的算法知识
pinned: 
---

## 前言

2020年初，我有幸加入了杜教授的图像与算法实验室，开始学习一些机器学习和图像识别的知识。最近学完了**机器学习的入门算法**知识，就在这里写写笔记吧。

补充中,最后更新:2020-03-05
<!-- more -->

最近人工智能挺火的，特别是基于深度学习的图像识别领域，现在的成功率已经远远高于人类的水平了。不过要学习深度学习，肯定是要先学习先修课程机器学习，还有一些基本的数理知识，比如**高数，线代，概率论，数分**等等。

## 机器学习简介

> 在不直接针对问题进行编程的情况下，赋予计算机学习能力的一个研究领域 --Arthur Samuel,1959

> 计算机算法的研究，并通过经验自动进行改善 --Tom M.Mitchell,1996

学术性来说，就是：对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随经验E而自我完善，那么我们称这个计算机程序在从经验E学习

通俗一点，就是：机器通过统计学算法，对大量的历史数据进行学习从而生成经验模型，利用经验模型指导业务。

21世纪三巨头：**Yoshua Bengio**,**Yann LeCun**,**Geoffrey Hinton**

## 有监督学习算法

### KNN - 最近邻接

KNN: K-Nearest Neighbour K个最近邻接点

#### 伪代码

```
循环:
    计算已知类别数据集中的点与 当前点 之间的距离
    按照距离递增次序排序
    if 样本点遍历完成:
        跳出循环
返回前 K 个样本点
统计 K 个样本点中出现频率最高的类别标签
```

### ID3 - 决策树

ID3: Iterative Dichotomiser 3 迭代树三代

#### 信息熵

由香农提出的，信息论里的概念，**描述混乱程度的度量**，取值范围**0~1**，值越大越混乱

信息熵计算公式，$p_i$为情况$i$的概率：

$$
H(U)=E[-log_2 p_i]=-\sum_{i=1}^{n}p_{i}log_2 p_i 
$$


#### 信息增益和特征选择

#### 伪代码

```
循环:
   选取当前最佳特征
   按照取值产生分支
   if 满足分支终止条件:
      if 无待处理分支:
          跳出循环
生成结果并处理
```

## 无监督学习算法

### K-Means - 聚类平均

#### 伪代码

```
选择K个点作为初始类簇中心
循环:
    将每个样本点指派到最近的类簇中心,形成K个类簇
    重新计算每个类簇的中心
    if 类簇不发生变化 or 达到最大迭代次数:
        跳出循环
分类完成
```

### Apriori - 先验关联

#### 最小支持度和置信度

#### 伪代码
```
确定最小支持度,最小置信度

确定1-频繁项集
确定2-频繁项集
确定3-频繁项集

确定关联规则
```

## 其他算法

### 半监督学习算法

### 集成学习

#### Bagging

#### Boosting

#### RandomForest - 随机森林

## 深度学习

## Reference
1. [CS229: Machine Learning](http://cs229.stanford.edu/)
2. [阿里云大学课程 https://edu.aliyun.com/lesson_838_7905](https://edu.aliyun.com/lesson_838_7905)
3. [Kaggle - course](https://www.kaggle.com/learn/intermediate-machine-learning)